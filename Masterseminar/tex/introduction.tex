The finger tree data structure can be viewed as a succession of refinements, the penultimate resulting in the dequeue introduced in the chapter on implicit recursive slowdown of~\cite{okasaki1999purely}. It was introduced in~\cite{hinze_paterson_2006} by Hinze and Paterson.

\subsection{Implicit Recursive Slowdown}

Okasaki positions his implicit recursive slowdown framework as a response to Kaplan's and Tarjan's recursive slowdown design principle~\cite{Kaplan:1995:PLC:225058.225090}. His refinement has looser restrictions on the structure of the data structure which results in simpler function, but his runtime bounds only match the originals after amortization.\par
The book~\cite{okasaki1999purely} motivates the  implicit recursive slowdown framework with natural number representations using lists, starting with a \mintinline{Haskell}{List} of bits, with the head being the LSB\@. This is the standard encoding, where to convert these lists to the ordinary decimal representation all digits are after using them as a weight to two to the power of their position.
\begin{minted}{Haskell}
    data Digit = Zero | One
    type Nat = [Digit]

    toInteger :: Nat -> Integer
    toInteger xs = sum $
        map (\(f,n) -> f * 2 ^ n) (zip (map fromEnum xs) [0..])
\end{minted}
Both \mintinline{Haskell}{inc} and \mintinline{Haskell}{dec} are implemented the obvious way. It is well known that the amortized complexity of both is \(\Theta(1)\). That can be proofed using the banker's method with the potential function \mintinline{Haskell}{Φ = length . elemIndices d}, with \texttt{d} being either \mintinline{Haskell}{One}, or \mintinline{Haskell}{Zero}. This is already indicative of the problem with this first iteration. While the desired bounds can be proofed for the isolated operations, the proofs are incompatible when supporting both operations at the same time, as they require different potential function. To correct this deficiency we allow our Digits to have three different values.
\begin{minted}{Haskell}
    data Digit = Zero | One | Two
\end{minted}
For converting this \mintinline{Haskell}{Nat} to an \mintinline{Haskell}{Integer}, the same function can be used. This introduces redundancy to our data structure, as evident by the lack of a bijection between \mintinline{Haskell}{Integer} and \mintinline{Haskell}{Nat}. The numbers \mintinline{Haskell}{[Two]} and \mintinline{Haskell}{[Zero,One]} map to the same \mintinline{Haskell}{Integer}. This is helpful because by allowing both operations we have lost our save digit. Before, in the context of \mintinline{Haskell}{inc}, the \mintinline{Haskell}{Zero} was the safe digit, meaning that execution always terminated when reaching it. With the extended \mintinline{Haskell}{Digit}, the \mintinline{Haskell}{One} is now a safe digit even when combining both operations. Now the previous bound can be shown with one new potential function attaching one debit to the safe digit and two to the dangerous ones.\par
To turn this into a useful data structure, we have to add data to the digits and replace the list with a more interesting type.
\begin{minted}{Haskell}
    data Digit a = One a | Two a a | Three a a a
    data RList a = Single (Digit a) 
        | Deep (Digit a) (RList (a, a))
\end{minted}
Instead of having the ability to representing a number be the primary function of this data structure, it merely indicates the number of elements stored. Before the value of a digit was determined by its position in the list. Now by handing down a tuple of the original element type, a tree-like structure is formed at the digits. This doubles the potential capacity of a digit with every level when descending into the structure.\par
For this new data structure implementations of \mintinline{Haskell}{cons}, \mintinline{Haskell}{head} and \mintinline{Haskell}{tail} can be found that all have an amortized complexity of \(\Theta(1)\). This is not particularly impressive, when considering, that \mintinline{Haskell}{List} has the same bounds, but doesn't require amortization. The advantage lies in accessing data deep into the data structure, while this problem can only be solved in linear time for lists, for an \mintinline{Haskell}{RList}, it can be done in \(\Theta(\log (n))\). To enable fast access to the end of the data structure, each \mintinline{Haskell}{Deep} node gets a second finger.
\begin{minted}{Haskell}
    data Digit a = One a | Two a a | Three a a a
    data RList a =
          Single (Digit a)
        | Deep (Digit a) (RList (a, a)) (Digit a) 
\end{minted}
The proof that all three operations have an amortized complexity of \(\Theta(1)\) on both ends can still be made using the banker's method.

\subsection{Type classes}

The implementation language for examples in this paper is Haskell. Two properties of it make it especially suited. In evaluation is generally lazy, without the need for dedicated commands and required for finger trees. The rich type system, especially its type classes, makes the code presentable in this context.\\
While the \mintinline{Haskell}{Monoid} and \mintinline{Haskell}{Foldable} classes were used, three additional ones were employed. For this paper, only the instructive instantiations of type classes will be presented.

\begin{minted}{Haskell}
    class Extendable a t where
        (<|) :: a -> t a -> t a 
        (|>) :: t a -> a -> t a
\end{minted}

A polymorphic type \mintinline{Haskell}{t} that implements \mintinline{Haskell}{Extendable a t}, has to provide an ap-/prepend operation.

\begin{minted}{Haskell}
    data View s a = Nil | Cons a (s a)

    class Viewable a t where
        viewL :: t a -> View t a
        viewR :: t a -> View t a
\end{minted}

\mintinline{Haskell}{Viewable a t} can be viewed as the dual to \mintinline{Haskell}{Extendable}, as it defines a way to separate the left-/rightmost element of type \mintinline{Haskell}{a} from a structure \mintinline{Haskell}{t a}.

\begin{minted}{Haskell}
    class Monoid v => Measured a v where
        μ :: a -> v
\end{minted}

An instantiation of the \mintinline{Haskell}{Measured a v} is meant to provide a way  the summarize a collection of type \mintinline{Haskell}{a}. This is done in a two-step process. Every value of type \mintinline{Haskell}{a} is first measured and assigned a value of type \mintinline{Haskell}{v}, which is required to of the instance of the \mintinline{Haskell}{Monoid} class. This way there is a guaranteed way to combine them into one final value of type \mintinline{Haskell}{v}.

\subsection{2-3 Trees}

\begin{minted}{Haskell}
    data Node v a = Node2 v a a | Node3 v a a a
\end{minted}

For these trees, the internal nodes don't hold any actual data. There is, however, a secondary value, used for caching measurements. The height invariant is enforced by the type, much like nested tuples used in Okasaki's \mintinline{Haskell}{RList}.

\begin{minted}{Haskell}
    Node2 (Node3 1 2 3) (Node2 4 5) :: Num a => Node (Node a)
\end{minted}